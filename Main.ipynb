{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem import WordNetLemmatizer #for noise removal \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re #Regex Library\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizerObject = WordNetLemmatizer()\n",
    "labels=[]\n",
    "tweets=[]\n",
    "def remove_noise(input_text):\n",
    "    noise_list = [\"a\", \"about\", \"after\", \"all\", \"also\", \"an\", \"another\", \"any\", \"and\", \"are\", \"as\", \"and\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"between\", \"but\", \"both\", \"by\", \"came\", \"can\", \"come\", \"could \", \"did\", \"do\", \"each\", \"even\", \"for\", \"from\", \"further\", \"furthermore\", \"get\", \"got\", \"has\", \"had\", \"he\", \"have\", \"her\", \"here\", \"him\", \"himself\", \"his\", \"how\", \"hi\", \"however\",\"i\", \"if\", \"in\", \"into\", \"is\", \"it\", \"its\", \"indeed\", \"just\", \"like\", \"made\", \"many\", \"me\", \"might\", \"more\", \"moreover\", \"most\", \"much\", \"must\", \"my never\", \"not\", \"now of\", \"on\", \"only\", \"other\", \"our\", \"out\", \"or\", \"over\", \"said\", \"same\", \"see\", \"should\", \"since\", \"she\", \"some\", \"still\", \"such\", \"take\", \"than\", \"that\", \"the\", \"their\", \"them\", \"then\", \"there\", \"these\", \"therefore\", \"they\", \"this\", \"those\", \"through\", \"to\", \"too\", \"thus\", \"under\", \"up\", \"was\", \"way\", \"we\", \"well\", \"were\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"will\", \"with\", \"would\", \"your\", \"null\"]\n",
    "    words = input_text.split() # Split words by space\n",
    "    noise_free_words = [word for word in words if word.lower() not in noise_list] #Get a list of non-noise words\n",
    "    noise_free_text = \" \".join(noise_free_words) #Get a string of non-noise words\n",
    "    return noise_free_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_regex(input_text):\n",
    "    #split tweet by space\n",
    "    words = input_text.split() \n",
    "    regex_free_text=\"\"\n",
    "    #check if word is alpha(contain letters only) , then add it to regex_free_text\n",
    "    for word in words:\n",
    "      if word.isalpha():\n",
    "        #Lemmatization, on the other hand, is an organized & step by step procedure of obtaining\n",
    "        #the root form of the word, it makes use of vocabulary (dictionary importance of words) \n",
    "        #and morphological analysis (word structure and grammar relations).\n",
    "        #reduces the inflected words properly ensuring that the root word belongs to the language\n",
    "        #pos=\"V\"-->to give a root for each word !\n",
    "        regex_free_text += lemmatizerObject.lemmatize(word,pos=\"v\")\n",
    "        regex_free_text +=\" \"\n",
    "    return regex_free_text\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(filename):\n",
    "    my_file = open(filename, encoding=\"utf-8\")\n",
    "    #return value of csv file is an iterator \n",
    "    read = csv.reader(my_file,delimiter='\\t')\n",
    "    #splitting = read.split('\\t')\n",
    "    flag=0;\n",
    "    #flag ---> used to skip the header of the file\n",
    "    #column one for tweets , column 2 for our ouput(NOT or OFF)\n",
    "    for row in read:\n",
    "      if flag ==0:\n",
    "        flag=1\n",
    "        continue;\n",
    "      tweets.append(row[1])\n",
    "      labels.append(row[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(ourTweets,ourTestTweets):   \n",
    "   vectorizer = TfidfVectorizer()\n",
    "   # return value ---> position of the word , index of tweet , tfidf value of the word.\n",
    "   X = vectorizer.fit_transform(ourTweets)\n",
    "   Y = vectorizer.transform(ourTestTweets)\n",
    "   return X,Y;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMClassifier(featuresTrain,labelsTrain,featuresTest):\n",
    "    #bn3ml training 3la train data (bn build our method 3aleha )\n",
    "    #f b3ml object mn classifier bt3i w b3den fit de bt3ml train lal data bt3ty\n",
    "    #tol---> nesbt el error el masbo7 beha el lw wsl 3ndha aw 2al yw2f w my7rksh el separator \n",
    "    #random_state is the seed used by the random number generator\n",
    "    #linear SVC da shbh precepton \n",
    "    clf = LinearSVC(random_state=0, tol=1e-5)\n",
    "    clf.fit(featuresTrain, labelsTrain)\n",
    "    #b predict b2a 3la test data bt3ty 3shn agib accuracy bt3t classifier da\n",
    "    X=clf.predict(featuresTest)\n",
    "    return X;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_Classifier(featuresTrain,labelsTrain,featuresTest):\n",
    "    clf = RandomForestClassifier(n_estimators=100)\n",
    "    clf.fit(featuresTrain, labelsTrain)\n",
    "        \n",
    "    return clf.predict(featuresTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticalRegression_Classifier(featuresTrain,labelsTrain,featuresTest):\n",
    "    clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "    clf.fit(featuresTrain, labelsTrain)\n",
    "    \n",
    "    return clf.predict(featuresTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayesClassifier(featuresTrain,labelsTrain,featuresTest):\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(featuresTrain, labelsTrain)\n",
    "    \n",
    "    return clf.predict(featuresTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNNClassifier(featuresTrain,labelsTrain,featuresTest):\n",
    "    clf = KNeighborsClassifier(n_neighbors=3)\n",
    "    clf.fit(featuresTrain, labelsTrain)\n",
    "    \n",
    "    return clf.predict(featuresTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of svm calssifier:\n",
      "0.7253776435045317\n",
      "\n",
      "\n",
      "accuracy of Random Forrest calssifier:\n",
      "0.7398791540785499\n",
      "\n",
      "\n",
      "accuracy of Logistic Regression calssifier:\n",
      "0.738821752265861\n",
      "\n",
      "\n",
      "accuracy of Naive Bayes calssifier:\n",
      "0.7078549848942598\n",
      "\n",
      "\n",
      "accuracy of KNN calssifier:\n",
      "0.682477341389728\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Confusion Matrix of SVM calssifier:\n",
      "\n",
      "[[3804  618]\n",
      " [1200  998]]\n",
      "\n",
      "\n",
      "Confusion Matrix of Random Forrest calssifier:\n",
      "\n",
      "[[4134  288]\n",
      " [1434  764]]\n",
      "\n",
      "\n",
      "Confusion Matrix of Logistical Regression calssifier:\n",
      "[[4112  310]\n",
      " [1419  779]]\n",
      "\n",
      "\n",
      "Confusion Matrix of Naive Bayes calssifier:\n",
      "\n",
      "[[4363   59]\n",
      " [1875  323]]\n",
      "\n",
      "\n",
      "Confusion Matrix of KNN calssifier:\n",
      "\n",
      "[[4359   63]\n",
      " [2039  159]]\n"
     ]
    }
   ],
   "source": [
    "def getAccuracy(outputLabels,actualLabels):\n",
    "      return accuracy_score(outputLabels, actualLabels)\n",
    "def calculateConfusionMatrix(outputLabels,actualLabels):\n",
    "    CM = confusion_matrix(actualLabels, outputLabels)\n",
    "    print(CM)\n",
    "readFile(\"offenseval-training-v1.tsv\")\n",
    "#loop for each tweet remove regex & noise\n",
    "for tweet in range(0,len(tweets)):\n",
    "    tweets[tweet]=remove_regex(tweets[tweet])\n",
    "    tweets[tweet]=remove_noise(tweets[tweet])\n",
    "#we have to divide our dataset into 2 parts (training data and test data)\n",
    "lenofLabel=(int)(len(labels)/2)\n",
    "lenofTweets=(int)(len(tweets)/2)\n",
    "train_labels=labels[:lenofLabel]\n",
    "test_labels=labels[lenofLabel:]\n",
    "train_tweets=tweets[:lenofLabel]\n",
    "test_tweets=tweets[lenofLabel:]\n",
    "#to extract Features\n",
    "features_train,features_test=extract_features(train_tweets,test_tweets)\n",
    "\n",
    "SVMpredictLabels = SVMClassifier(features_train,train_labels,features_test)\n",
    "RFpredictLabels = RandomForest_Classifier(features_train,train_labels,features_test)\n",
    "LRpredictLabels = LogisticalRegression_Classifier(features_train,train_labels,features_test)\n",
    "NBpredictLabels=NaiveBayesClassifier(features_train,train_labels,features_test)\n",
    "KNNpredictLabels=KNNClassifier(features_train,train_labels,features_test)\n",
    "#calculate accuracy of predicted labels (from our algorithm ) & the actual labels\n",
    "SVMaccuracy=getAccuracy(SVMpredictLabels,test_labels)\n",
    "RFaccuracy=getAccuracy(RFpredictLabels,test_labels)\n",
    "LRaccuracy=getAccuracy(LRpredictLabels,test_labels)\n",
    "NBaccuracy=getAccuracy(NBpredictLabels,test_labels)\n",
    "KNNaccuracy=getAccuracy(KNNpredictLabels,test_labels)\n",
    "\n",
    "print(\"accuracy of svm calssifier:\")\n",
    "print(SVMaccuracy)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"accuracy of Random Forrest calssifier:\")\n",
    "print(RFaccuracy)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"accuracy of Logistic Regression calssifier:\")\n",
    "print(LRaccuracy)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"accuracy of Naive Bayes calssifier:\")\n",
    "print(NBaccuracy)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"accuracy of KNN calssifier:\")\n",
    "print(KNNaccuracy)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrix of SVM calssifier:\\n\")\n",
    "calculateConfusionMatrix(SVMpredictLabels,test_labels)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrix of Random Forrest calssifier:\\n\")\n",
    "calculateConfusionMatrix(RFpredictLabels,test_labels)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrix of Logistical Regression calssifier:\")\n",
    "calculateConfusionMatrix(LRpredictLabels,test_labels)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrix of Naive Bayes calssifier:\\n\")\n",
    "calculateConfusionMatrix(NBpredictLabels,test_labels)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Confusion Matrix of KNN calssifier:\\n\")\n",
    "calculateConfusionMatrix(KNNpredictLabels,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
