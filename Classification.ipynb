{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import nltk.stem\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.stats import expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        self.lemmatizer_object = nltk.stem.WordNetLemmatizer()\n",
    "        self.labels = []\n",
    "        self.tweets = []\n",
    "        Preprocessing.readFile(self,\"offenseval-training-v1.tsv\")\n",
    "        Preprocessing.divide_data_set(self)\n",
    "\n",
    "    def remove_noise(self,input_text):\n",
    "        noise_list = [\"a\", \"about\", \"after\", \"all\", \"also\", \"an\", \"another\", \"any\", \"and\", \"are\", \"as\", \"and\", \"at\",\n",
    "                      \"be\",\n",
    "                      \"because\", \"been\", \"before\", \"being\", \"between\", \"but\", \"both\", \"by\", \"came\", \"can\", \"come\",\n",
    "                      \"could \",\n",
    "                      \"did\", \"do\", \"each\", \"even\", \"for\", \"from\", \"further\", \"furthermore\", \"get\", \"got\", \"has\", \"had\",\n",
    "                      \"he\", \"have\", \"her\", \"here\", \"him\", \"himself\", \"his\", \"how\", \"hi\", \"however\", \"i\", \"if\", \"in\",\n",
    "                      \"into\",\n",
    "                      \"is\", \"it\", \"its\", \"indeed\", \"just\", \"like\", \"made\", \"many\", \"me\", \"might\", \"more\", \"moreover\",\n",
    "                      \"most\", \"much\", \"must\", \"my never\", \"not\", \"now of\", \"on\", \"only\", \"other\", \"our\", \"out\", \"or\",\n",
    "                      \"over\", \"said\", \"same\", \"see\", \"should\", \"since\", \"she\", \"some\", \"still\", \"such\", \"take\", \"than\",\n",
    "                      \"that\", \"the\", \"their\", \"them\", \"then\", \"there\", \"these\", \"therefore\", \"they\", \"this\", \"those\",\n",
    "                      \"through\", \"to\", \"too\", \"thus\", \"under\", \"up\", \"was\", \"way\", \"we\", \"well\", \"were\", \"what\", \"when\",\n",
    "                      \"where\", \"which\", \"while\", \"who\", \"will\", \"with\", \"would\", \"your\", \"null\"]\n",
    "        words = input_text.split()  # Split words by space\n",
    "        noise_free_words = [word for word in words if word.lower() not in noise_list]  # Get a list of non-noise words\n",
    "        noise_free_text = \" \".join(noise_free_words)  # Get a string of non-noise words\n",
    "        return noise_free_text\n",
    "\n",
    "    def remove_regex(self,input_text):\n",
    "        # split tweet by space\n",
    "        words = input_text.split()\n",
    "        regex_free_text = \"\"\n",
    "        # check if word is alpha(contain letters only) , then add it to regex_free_text\n",
    "        for word in words:\n",
    "            if word.isalpha():\n",
    "                # Lemmatization, on the other hand, is an organized & step by step procedure of obtaining\n",
    "                # the root form of the word, it makes use of vocabulary (dictionary importance of words)\n",
    "                # and morphological analysis (word structure and grammar relations).\n",
    "                # reduces the inflected words properly ensuring that the root word belongs to the language\n",
    "                # pos=\"V\"-->to give a root for each word !\n",
    "                regex_free_text += self.lemmatizer_object.lemmatize(word, pos=\"v\")  # V Msdr\n",
    "                regex_free_text += \" \"\n",
    "        return regex_free_text\n",
    "\n",
    "    def readFile(self,filename):\n",
    "        my_file = open(filename, encoding=\"utf-8\")\n",
    "        # return value of csv file is an iterator\n",
    "        read = csv.reader(my_file, delimiter='\\t')\n",
    "        # splitting = read.split('\\t')\n",
    "        flag = 0\n",
    "        # flag ---> used to skip the header of the file\n",
    "        # column one for tweets , column 2 for our ouput(NOT or OFF)\n",
    "        for row in read:\n",
    "            if flag == 0:\n",
    "                flag = 1\n",
    "                continue;\n",
    "            self.tweets.append(row[1])\n",
    "            self.labels.append(row[2])\n",
    "\n",
    "    def divide_data_set(self):\n",
    "        # loop for each tweet remove regex & noise\n",
    "        for tweet in range(0, len(self.tweets)):\n",
    "            self.tweets[tweet] = Preprocessing.remove_regex(self,self.tweets[tweet])\n",
    "            self.tweets[tweet] = Preprocessing.remove_noise(self,self.tweets[tweet])\n",
    "        # we have to divide our dataset into 2 parts (training data and test data)\n",
    "        lenofLabel = (int)(len(self.labels) / 2)\n",
    "        self.lenofTweets = (int)(len(self.tweets) / 2)\n",
    "        self.train_labels = self.labels[:lenofLabel]\n",
    "        self.test_labels = self.labels[lenofLabel:]\n",
    "        self.train_tweets = self.tweets[:lenofLabel]\n",
    "        self.test_tweets = self.tweets[lenofLabel:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "    prep = Preprocessing()\n",
    "    train_labels = prep.train_labels\n",
    "    test_labels = prep.test_labels\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    features_train = vectorizer.fit_transform(prep.train_tweets)\n",
    "    features_test = vectorizer.transform(prep.test_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal C: 0.001\n",
      "0.66797583081571\n",
      "[[4422    0]\n",
      " [2198    0]]\n"
     ]
    }
   ],
   "source": [
    "    #SVM_Classifier\n",
    "    C = list(np.arange(0.001,1,0.001))\n",
    "    cv_scores = []\n",
    "    for c in C:\n",
    "        clf = LinearSVC(C = c)\n",
    "        scores = cross_val_score(clf, features_test, train_labels, cv = 10, scoring = 'accuracy')\n",
    "        cv_scores.append(scores.mean())\n",
    "    MSE = [1 - x for x in cv_scores]\n",
    "    optimal_c = C[MSE.index(min(MSE))]\n",
    "    plt.plot(C, MSE)\n",
    "    plt.xlabel('C')\n",
    "    plt.ylabel('Misclassification Error')\n",
    "    plt.show()\n",
    "    print(\"Optimal C: \" + str(optimal_c))\n",
    "    # bn3ml training 3la train data (bn build our method 3aleha )\n",
    "    # f b3ml object mn classifier bt3i w b3den fit de bt3ml train lal data bt3ty\n",
    "    # tol---> nesbt el error el masbo7 beha el lw wsl 3ndha aw 2al yw2f w my7rksh el separator\n",
    "    # random_state is the seed used by the random number generator\n",
    "    # linear SVC da shbh precepton\n",
    "    clf = LinearSVC(C = optimal_c,random_state=0, tol=1e-5)\n",
    "    clf.fit(features_train, train_labels)\n",
    "    output_labels = clf.predict(features_test)\n",
    "    # b predict b2a 3la test data bt3ty 3shn agib accuracy bt3t classifier da\n",
    "    print(accuracy_score(output_labels, test_labels))\n",
    "    print(confusion_matrix(test_labels, output_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Logistic Regression Classifier\n",
    "    np.set_printoptions(formatter={'float_kind':lambda x: \"%.4f\" % x})\n",
    "    lr = LogisticRegression()\n",
    "    lr_params = {'C': expon()}\n",
    "    lr_random = RandomizedSearchCV(estimator = lr, param_distributions = lr_params, n_iter = 50, cv = 5, verbose=0)\n",
    "    lr_random.fit(features_train, train_labels)\n",
    "    print(lr_random.best_params_)\n",
    "    print(lr_random.best_score_)      \n",
    "    scores=[]\n",
    "    Cs=[]\n",
    "    finalC=[]\n",
    "    scores=lr_random.cv_results_['mean_test_score']\n",
    "    Cs=lr_random.cv_results_['params']\n",
    "    for c in Cs:\n",
    "        if 'C' in c:\n",
    "            finalC.append(c['C'])\n",
    "    print(scores)\n",
    "    print(finalC)\n",
    "    plt.plot(finalC, scores)\n",
    "    plt.xlabel('Value of C')\n",
    "    plt.ylabel('Score')\n",
    "    plt.show()\n",
    "    #Rowan parameters ---->       \n",
    "    clf = LogisticRegression(C=1.4, solver='liblinear', multi_class='auto')\n",
    "    clf.fit(features_train, train_labels)\n",
    "    output_labels = clf.predict(features_test)\n",
    "    print(accuracy_score(output_labels, test_labels))\n",
    "    print(confusion_matrix(test_labels, output_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Random-Forest Classifier\n",
    "    \n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 5, 10]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True, False]\n",
    "    # Create the random grid\n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "    \n",
    "    # Use the random grid to search for best hyperparameters\n",
    "    # First create the base model to tune\n",
    "    rf = RandomForestClassifier()\n",
    "    # Random search of parameters, using 3 fold cross validation, \n",
    "    # search across 100 different combinations, and use all available cores\n",
    "    #cv---> 3dad el folds , n_iter kam combination ygrbha , estimator eh hwa classifier el 7y3ml tuning , n_jobs 3dad el cores                 el 7ysh3'lha verbose--->btktb m3lomat 3n running\n",
    "    rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 50, cv = 4, verbose=0,              \n",
    "    random_state=42, n_jobs=-1, refit=True)\n",
    "    # Fit the random search models\n",
    "    rf_random.fit(features_train, train_labels)\n",
    "    print(rf_random.best_params_)\n",
    "    #Merna's parameters ---->\n",
    "    clf = RandomForestClassifier(n_estimators=600,min_samples_split = 2, min_samples_leaf = 2,max_features = 'sqrt',         \n",
    "    max_depth = 110)\n",
    "    clf.fit(features_train, labels_train)  \n",
    "    output_labels = clf.predict(features_test)\n",
    "    print(accuracy_score(output_labels, test_labels))\n",
    "    print(confusion_matrix(test_labels, output_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Naive-Bayes Classifier\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(features_train, labels_train)\n",
    "    output_labels = fit.predict(features_test)\n",
    "    print(accuracy_score(output_labels, test_labels))\n",
    "    print(confusion_matrix(test_labels, output_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #KNN Classifier\n",
    "    neighbors = list(range(1,50))\n",
    "    cv_scores = []\n",
    "    for k in neighbors:\n",
    "        knn = KNeighborsClassifier(n_neighbors=k)\n",
    "        scores = cross_val_score(knn, trainFeatures, trainLabel, cv=10, scoring='accuracy')\n",
    "        cv_scores.append(scores.mean())\n",
    "    MSE = [1 - x for x in cv_scores]\n",
    "    optimal_k = neighbors[MSE.index(min(MSE))]\n",
    "    print(optimal_k)\n",
    "    plt.plot(neighbors, MSE)\n",
    "    plt.xlabel('Number of Neighbors K')\n",
    "    plt.ylabel('Misclassification Error')\n",
    "    plt.show()\n",
    "    clf = KNeighborsClassifier(n_neighbors = optimal_k)\n",
    "    clf.fit(features_train, labels_train)\n",
    "    output_labels = clf.predict(features_test)\n",
    "    print(accuracy_score(output_labels,test_labels))\n",
    "    print(confusion_matrix(test_labels, output_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #Decision-Trees Classifier\n",
    "    depth = list(range(1,100))\n",
    "    cv_scores_gini = []\n",
    "    cv_scores_entropy = []\n",
    "    ans = \"\"\n",
    "    for m in depth:\n",
    "        dt_gini = DecisionTreeClassifier(max_depth = m)\n",
    "        dt_entropy = DecisionTreeClassifier(criterion = 'entropy',max_depth = m)\n",
    "        scores_gini = cross_val_score(dt_gini, trainFeatures, trainLabel, cv=5, scoring='accuracy')\n",
    "        scores_entropy = cross_val_score(dt_gini, trainFeatures, trainLabel, cv=5, scoring='accuracy')\n",
    "        cv_scores_gini.append(scores_gini.mean())\n",
    "        cv_scores_entropy.append(scores_entropy.mean())\n",
    "    MSE_entropy = [1 - x for x in cv_scores_entropy]\n",
    "    MSE_gini = [1 - x for x in cv_scores_gini]\n",
    "    optimal_d_entropy = depth[MSE_entropy.index(min(MSE_entropy))]\n",
    "    optimal_d_gini = depth[MSE_gini.index(min(MSE_gini))]\n",
    "    if(optimal_d_entropy >= optimal_d_gini):\n",
    "        print(\"Entropy: \" + str(optimal_d_entropy) + \"\\n\")\n",
    "        ans = \"entropy\"\n",
    "    else:\n",
    "        print(\"Gini: \" + str(optimal_d_gini) + \"\\n\")\n",
    "        ans = \"gini\"\n",
    "    plot1, = plt.plot(depth, MSE_entropy, label ='Entropy')\n",
    "    plt.xlabel('Tree depth')\n",
    "    plt.ylabel('Misclassification Error')\n",
    "    plt.show()\n",
    "    plot2, = plt.plot(depth, MSE_gini, label = 'Gini')\n",
    "    plt.xlabel('Tree depth')\n",
    "    plt.ylabel('Misclassification Error')\n",
    "    plt.legend(handles=[plot1, plot2])\n",
    "    plt.show()\n",
    "    tree_clf = DecisionTreeClassifier(criterion = str(ans) , max_depth = int(max([optimal_d_entropy,optimal_d_gini])))\n",
    "    tree_clf.fit(features_train, labels_train)\n",
    "    output_labels = tree_clf.predict(features_test)\n",
    "    print(accuracy_score(output_labels,test_labels))\n",
    "    print(accuracy_score())\n",
    "    print(confusion_matrix(test_labels, output_labels))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
